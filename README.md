# Wikipedia Analyzer - Backend

Este es el backend de **Wikipedia Analyzer**, una aplicaci칩n que permite buscar art칤culos de Wikipedia, analizarlos ling칲칤sticamente (palabras clave, sentimiento, entidades nombradas), y guardarlos para su posterior revisi칩n.

## 游 Funcionalidad principal

- Buscar art칤culos en Wikipedia.
- Obtener resumen y contenido completo.
- Analizar texto: palabras clave, an치lisis de sentimiento y entidades nombradas.
- Guardar art칤culos analizados con notas opcionales.
- Listar art칤culos guardados.

Todos los endpoints est치n documentados en Swagger:
游녤 http://localhost:8000/docs


## 游 Tecnolog칤as usadas

- **FastAPI**: Framework backend asincr칩nico en Python.
- **Prisma (via Prisma Client Python)**: ORM para conectarse con la base de datos PostgreSQL.
- **TextBlob**: An치lisis de sentimiento y palabras m치s comunes.
- **spaCy**: Detecci칩n de entidades nombradas (NLP).
- **Uvicorn**: Servidor ASGI para correr FastAPI.
- **Docker / Docker Compose**: Contenedores para el entorno de ejecuci칩n.


## 丘뙖잺 C칩mo correr el backend

### Opci칩n recomendada (Docker)

```bash
docker-compose up --buil
```

- Backend disponible en http://localhost:8000
- PostgreSQL ya configurado
- Migraciones autom치ticas

### Opci칩n manual (sin Docker)

```bash
python -m venv venv
source venv/bin/activate  # o venv\Scripts\activate en Windows
pip install -r requirements.txt
cd app
python main.py
```
NOTA: Aseg칰rate de tener un PostgreSQL local y configurar DATABASE_URL en .env.


## Apuntes t칠cnicos importantes a resaltar

- TextBlob evita dependencias pesadas como NLTK para an치lisis de texto b치sico (ya maneja tokenizaci칩n y sentimiento).

- spaCy (modelo en ingl칠s) es m치s confiable que NLTK para NER.

- Top palabras se filtran usando solo tokens alfab칠ticos y excluyen stopwords.

- Prisma facilita el trabajo con PostgreSQL y mantiene el esquema tipado.