# Wikipedia Analyzer 

Este es el proyecto de **Wikipedia Analyzer**, una aplicaci칩n que permite buscar art칤culos de Wikipedia, analizarlos ling칲칤sticamente (palabras clave, sentimiento, entidades nombradas), y guardarlos para su posterior revisi칩n.

## 游 Funcionalidad principal

- Buscar art칤culos en Wikipedia.
- Obtener resumen y contenido completo.
- Analizar texto: palabras clave, an치lisis de sentimiento.
- Temas principales, Palabras mas repetidas, complejidad texto, oraciones, palabras/oracion, min. de lectura.
- Insights claves sobre el articulo
- Guardar art칤culos analizados con notas opcionales.
- Listar art칤culos guardados.

Todos los endpoints est치n documentados en Swagger:
游녤 http://localhost:8000/docs


## 游 Tecnolog칤as usadas

- **FastAPI**: Framework backend asincr칩nico en Python.
- **SQLAlchemy**: ORM para conectarse con la base de datos PostgreSQL.
- **TextBlob**: An치lisis de sentimiento y palabras m치s comunes.
- **spaCy**: Detecci칩n de entidades nombradas (NLP).
- **Uvicorn**: Servidor ASGI para correr FastAPI.
- **Frontend**: Se utiliz칩 Next js para la realziaci칩n del frontend


## 丘뙖잺 C칩mo correr el backend

```bash
python -m venv venv
source venv/bin/activate  # o venv\Scripts\activate en Windows
pip install -r requirements.txt
cd backend/app
python main.py
```
NOTA: Aseg칰rate de tener un PostgreSQL local y configurar DATABASE_URL en .env.


## 丘뙖잺 C칩mo correr el Frontend

```bash
cd frontend
npm i
npm run dev
```

NOTA: Aseg칰rate de tener NEXT_PUBLIC_API_URL = http://localhost:8000 en .env.

## Apuntes t칠cnicos importantes a resaltar

- TextBlob evita dependencias pesadas como NLTK para an치lisis de texto b치sico (ya maneja tokenizaci칩n y sentimiento).

- spaCy (modelo en ingl칠s) es m치s confiable que NLTK para NER.

- Top palabras se filtran usando solo tokens alfab칠ticos y excluyen stopwords.

- An치lisis b치sico realizado para dar mayor informaci칩n sobre el art칤culo de manera resumida.